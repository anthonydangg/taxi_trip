{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63e3837",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from datetime import datetime\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe27888e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8763734",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07939271",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#only 10 rows with missing data just dropping\n",
    "data = data[data['MISSING_DATA'] == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d2774d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def polyline_to_trip_duration(polyline):\n",
    "    return max(polyline.count(\"[\") - 2, 0) * 15 #subtracting 2 because one is for the opening bracket?\n",
    "\n",
    "# This code creates a new column, \"LEN\", in our dataframe. The value is\n",
    "# the (polyline_length - 1) * 15, where polyline_length = count(\"[\") - 1\n",
    "data[\"LEN\"] = data[\"POLYLINE\"].apply(polyline_to_trip_duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9790a30",
   "metadata": {},
   "source": [
    "**Making time columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8332458",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_time(x):\n",
    "    dt = datetime.fromtimestamp(x[\"TIMESTAMP\"])\n",
    "    return dt.year, dt.month, dt.day, dt.hour, dt.weekday()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fcc43300",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[[\"YR\", \"MON\", \"DAY\", \"HR\", \"WK\"]] = (\n",
    "    data[[\"TIMESTAMP\"]].apply(parse_time, axis=1, result_type=\"expand\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "827c6052",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filling nan's with -1 to avoid errors\n",
    "data['ORIGIN_STAND'].fillna(-1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f130faa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#since the data is very wide after onehotencoding, we'll do a 85-15 split to give the model more data\n",
    "train, valid = train_test_split(data, train_size = 0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06d4a98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "del data  #clearing memory since this dataframe is now redundant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4b5c61",
   "metadata": {},
   "source": [
    "**Add interaction terms** ?\n",
    "- day * hour (both categorical)\n",
    "- hour * origin stand\n",
    "- day_type * origin stand"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543c7631",
   "metadata": {},
   "source": [
    "## Data engineering\n",
    "- Should all the features be categorical? Seems wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ae48df5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['TRIP_ID', 'CALL_TYPE', 'ORIGIN_CALL', 'ORIGIN_STAND', 'TAXI_ID',\n",
       "       'TIMESTAMP', 'DAY_TYPE', 'MISSING_DATA', 'POLYLINE', 'LEN', 'YR', 'MON',\n",
       "       'DAY', 'HR', 'WK'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns\n",
    "#independent variables are: call_type, origin_call, origin_stand, yr, mon, day, hr, week\n",
    "#all categorical?\n",
    "\n",
    "# most origin call are NaN (~78% of training data). probably drop, not sure how we'd infer it\n",
    "# about 52% of origin_stand are NaN. should we impute?\n",
    "#no NaN in call_type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "21d961ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train[[\"YR\", \"MON\", \"DAY\", \"HR\", \"WK\", 'ORIGIN_STAND', 'CALL_TYPE']]\n",
    "Y_train = train[\"LEN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4af89deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid = valid[[\"YR\", \"MON\", \"DAY\", \"HR\", \"WK\", 'ORIGIN_STAND', 'CALL_TYPE']] \n",
    "Y_valid = valid[\"LEN\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba704b6e",
   "metadata": {},
   "source": [
    "## Using one hot encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f7d9452",
   "metadata": {},
   "outputs": [],
   "source": [
    "##why is this not working?\n",
    "#X_train['CALL_TYPE'] = X_train['CALL_TYPE'].astype(str) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "104f2d95",
   "metadata": {},
   "outputs": [],
   "source": [
    " #probably want to do an embedding instead\n",
    "encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "\n",
    "# Fit the encoder on the training data\n",
    "encoder.fit(X_train[X_train.columns])\n",
    "X_train_OH = encoder.transform(X_train[X_train.columns])\n",
    "\n",
    "X_train = torch.Tensor(X_train_OH).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a7e12ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "dataset = torch.utils.data.TensorDataset(X_train, torch.from_numpy(Y_train.values))\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "423f2da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(DeepModel, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(hidden_size), #added batchnorm\n",
    "            nn.Linear(hidden_size, hidden_size), #added another hidden layer compared to writeup\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, data):\n",
    "        \n",
    "        # Pass through the encoder\n",
    "        output = self.encoder(data)\n",
    "        \n",
    "        return output.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "da7a50a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeeperModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(DeeperModel, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(hidden_size, 2*hidden_size), #added another hidden layer compared to writeup\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(2*hidden_size, hidden_size), #added another hidden layer compared to writeup\n",
    "            nn.LeakyReLU(),\n",
    "            nn.BatchNorm1d(hidden_size), #added batchnorm, is this correct?\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(hidden_size, 100),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(100, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, data):\n",
    "        \n",
    "        # Pass through the encoder\n",
    "        output = self.encoder(data)\n",
    "        \n",
    "        return output.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "96266937",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1454061, 143])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a31701b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 512 #large because of the onehot encoding, we need a wide model\n",
    "\n",
    "model = DeepModel(X_train.size(1),\n",
    "                   hidden_size).to(device)\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dffccc37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------\n",
      "Time of epoch 1: 90.52183127403259 seconds\n",
      "Epoch 1 loss: 676.5313940276085\n",
      "-------------------------------\n",
      "Time of epoch 2: 88.44004917144775 seconds\n",
      "Epoch 2 loss: 672.5542773750587\n",
      "-------------------------------\n",
      "Time of epoch 3: 86.33437442779541 seconds\n",
      "Epoch 3 loss: 671.6402689569618\n",
      "-------------------------------\n",
      "Time of epoch 4: 87.20733737945557 seconds\n",
      "Epoch 4 loss: 670.9992826797823\n",
      "-------------------------------\n",
      "Time of epoch 5: 86.47479748725891 seconds\n",
      "Epoch 5 loss: 670.4705371084357\n"
     ]
    }
   ],
   "source": [
    "#deep network\n",
    "\n",
    "\n",
    "\n",
    "losses = []\n",
    "for epoch in range(5):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    running_loss = 0\n",
    "    n = 0\n",
    "    \n",
    "    print(f\"-------------------------------\")\n",
    "    \n",
    "\n",
    "    # Loop over batches in an epoch using DataLoader\n",
    "    for batch_idx, (x_batch, y_batch) in enumerate(train_loader):\n",
    "        \n",
    "        x_batch = x_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "    \n",
    "\n",
    "        y_batch_pred = model(x_batch)\n",
    "\n",
    "\n",
    "        loss = loss_fn(y_batch_pred, y_batch.float())\n",
    "        running_loss += loss.item()\n",
    "        n += 1\n",
    "\n",
    "        # backwards steps\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f'Time of epoch {epoch + 1}: {time.time() - start_time} seconds')\n",
    "        \n",
    "    print(f\"Epoch {epoch + 1} loss: {np.sqrt(running_loss/n)}\")\n",
    "    losses.append(np.sqrt(running_loss/n))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "cc4583db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#how to stop loss from converging here? need a more complex model? \n",
    "    #A: one hot encoding makes the data sparse, so we need a much wider model. \n",
    "    #with this additional width, we need to make the model deeper as well in order to make sure\n",
    "    #it sees enough data\n",
    "#should we do a different encoding?\n",
    "\n",
    "#why is loss so different on validation vs test? which loss should we believe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7469ae4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)\n",
    "plt.ylabel('Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.savefig('loss_by_epoch.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f5d412e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid_OH = encoder.transform(X_valid[X_valid.columns])\n",
    "\n",
    "X_valid_OH = torch.Tensor(X_valid_OH).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8b6c6ddb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 315,  255,  195, ..., 1350,  750,  390])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_valid.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9e94aa00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "664.5225"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_preds = model(X_valid_OH)\n",
    "np.sqrt(\n",
    "    F.mse_loss(val_preds.cpu(), \n",
    "               torch.Tensor(Y_valid.values)).detach().numpy()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7964dfb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.42068363477644105\n"
     ]
    }
   ],
   "source": [
    "print(pd.Series(val_preds.detach().cpu()).nunique()/len(val_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5e7cbe",
   "metadata": {},
   "source": [
    "### Analyzing trips which were hard to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3001f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#not enough memory\n",
    "y_train_pred = model.cpu()(X_train.cpu())\n",
    "with_preds = train.copy()\n",
    "with_preds['diff'] = abs(train['LEN'] - y_train_pred)\n",
    "\n",
    "ten_worst = with_preds.sort_values(by = 'diff', ascending = False).iloc[:10][['POLYLINE', 'diff']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bdb3be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_polyline(polyline):\n",
    "    x = [point[0] for point in polyline]\n",
    "    y = [point[1] for point in polyline]\n",
    "\n",
    "    plt.plot(x, y, '-o')\n",
    "    plt.xlabel('X')\n",
    "    plt.ylabel('Y')\n",
    "    plt.title('Polyline Plot')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    plot_polyline(\n",
    "        eval(\n",
    "            ten_worst.reset_index()['POLYLINE'].iloc[i]\n",
    "        )\n",
    "        )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5451e0c3",
   "metadata": {},
   "source": [
    "### Prediction file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b8bb6074",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('test_public.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "bcd640ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data[[\"YR\", \"MON\", \"DAY\", \"HR\", \"WK\"]] = (\n",
    "    test_data[[\"TIMESTAMP\"]].apply(parse_time, axis=1, result_type=\"expand\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "da628172",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_data[[\"YR\", \"MON\", \"DAY\", \"HR\", \"WK\", 'ORIGIN_STAND', 'CALL_TYPE']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0ced1938",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_OH = encoder.transform(X_test[X_test.columns])\n",
    "\n",
    "X_test = torch.Tensor(X_test_OH).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "58a27989",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "717e4e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_preds = pd.DataFrame({'TRIP_ID': test_data['TRIP_ID'], 'TRAVEL_TIME': train['LEN'].mean()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6d0198bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_preds = pd.DataFrame({'TRIP_ID': test_data['TRIP_ID'], 'TRAVEL_TIME': preds.cpu().detach()})\n",
    "\n",
    "final_preds.to_csv('underfit_test_preds.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5380c2b8",
   "metadata": {},
   "source": [
    "## Embedding\n",
    "\n",
    "**Not in use**  \n",
    "We still need to debug this, but it's our idea for how to improve the model next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d021a04c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['CALL_TYPE', 'ORIGIN_STAND', 'TIMESTAMP', 'YR', 'MON', 'DAY', 'HR',\n",
      "       'WK'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataframe, dropped_columns):\n",
    "        self.data = dataframe.drop(columns=dropped_columns)#.values\n",
    "        self.targets = dataframe[\"LEN\"].astype(float).values\n",
    "        print(self.data.columns)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        print(self.data[idx])\n",
    "        x = torch.tensor(self.data[idx], dtype=torch.float32)\n",
    "        y = torch.tensor(self.targets[idx], dtype=torch.float32)\n",
    "        return x, y\n",
    "\n",
    "\n",
    "dataset = CustomDataset(train, dropped_columns=['LEN', 'POLYLINE', \n",
    "                                                'MISSING_DATA', 'TRIP_ID', 'ORIGIN_CALL',\n",
    "                                               \"DAY_TYPE\", 'TAXI_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5069975",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PandasDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.targets = dataframe[\"LEN\"].astype(float).values\n",
    "        self.data = dataframe[['CALL_TYPE', 'ORIGIN_STAND', 'YR', 'MON', 'DAY', 'HR', 'WK']]\n",
    "        self.call_type_mapping = {'A': 0, 'B': 1, 'C': 2}\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = self.data.iloc[idx, :].copy()\n",
    "        x['CALL_TYPE'] = self.call_type_mapping[x['CALL_TYPE']]\n",
    "        \n",
    "        y = torch.tensor(self.targets[idx], dtype=torch.float32)\n",
    "     \n",
    "        return torch.from_numpy(x.values.astype(np.float32)), y\n",
    "\n",
    "dataset = PandasDataset(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d070c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b70e5c6",
   "metadata": {},
   "source": [
    "# Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7b607386",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7f9dc999",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicModel(nn.Module):\n",
    "    def __init__(self, num_call_types, num_origin_stands, embedding_dim, hidden_size):\n",
    "        super(BasicModel, self).__init__()\n",
    "        \n",
    "        # Embedding layers\n",
    "        self.call_type_embedding = nn.Embedding(num_call_types, embedding_dim)\n",
    "        self.origin_stand_embedding = nn.Embedding(num_origin_stands, embedding_dim)\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(24, hidden_size), \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, data):\n",
    "        call_type_embedded = self.call_type_embedding(call_type)\n",
    "\n",
    "\n",
    "        print(origin_stand)\n",
    "\n",
    "        # Getting values from embedding\n",
    "        origin_stand_embedded = self.origin_stand_embedding(origin_stand)\n",
    "\n",
    "        hour = hour.unsqueeze(1)\n",
    "        day = day.unsqueeze(1)\n",
    "        month = month.unsqueeze(1)\n",
    "        year = year.unsqueeze(1)\n",
    "\n",
    "        # Concatenating\n",
    "        features = torch.cat([hour, day, month, year, call_type_embedded, origin_stand_embedded], dim=1)\n",
    "\n",
    "        output = self.encoder(features)\n",
    "        \n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "faee631a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#not sure about input size\n",
    "num_call_types = train['CALL_TYPE'].nunique() \n",
    "num_origin_stands = train['ORIGIN_STAND'].nunique() \n",
    "embedding_dim = 10 #arbitrary\n",
    "hidden_size = 64 #arbitrary\n",
    "\n",
    "model = BasicModel(num_call_types, \n",
    "                   num_origin_stands, embedding_dim, \n",
    "                   hidden_size).to(device)\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ac343b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_85/831059653.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# Loop over batches in an epoch using DataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mx_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_loader' is not defined"
     ]
    }
   ],
   "source": [
    "#deep network (not lstm)\n",
    "\n",
    "for epoch in range(5):\n",
    "    \n",
    "    running_loss = 0\n",
    "    n = 0\n",
    "    \n",
    "    print(f\"Epoch {epoch + 1}\\n-------------------------------\")\n",
    "\n",
    "    # Loop over batches in an epoch using DataLoader\n",
    "    for batch_idx, (x_batch, y_batch) in enumerate(train_loader):\n",
    "        \n",
    "        x_batch = x_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "        \n",
    "        \n",
    "        \n",
    "        call_type = x_batch[:, 0].long()\n",
    "        origin_stand = x_batch[:, 1].long()\n",
    "        year = x_batch[:, 2]  \n",
    "        month = x_batch[:, 3]  \n",
    "        day = x_batch[:, 4]\n",
    "        hour = x_batch[:, 5]\n",
    "        week = x_batch[:, 6]\n",
    "        \n",
    "        min_origin_stand = torch.min(origin_stand)\n",
    "        origin_stand_processed = origin_stand - min_origin_stand\n",
    "\n",
    "        y_batch_pred = model(hour, day, month, year, call_type, origin_stand_processed)\n",
    "\n",
    "\n",
    "        loss = loss_fn(y_batch_pred[0], y_batch.float())\n",
    "        running_loss += loss.item()\n",
    "        n += 1\n",
    "\n",
    "        # backwards steps\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        \n",
    "    print(f\"Epoch {epoch + 1} loss: {running_loss/n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ebeb43ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "Epoch 1 loss: 474716.41855863854\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Epoch 2 loss: 474706.96882588905\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Epoch 3 loss: 474695.4468317422\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Epoch 4 loss: 474669.8388911181\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Epoch 5 loss: 474651.3308392597\n"
     ]
    }
   ],
   "source": [
    "hidden_state = (torch.zeros(1, hidden_size).to(device),\n",
    "                torch.zeros(1, hidden_size).to(device))\n",
    "\n",
    "# https://stackoverflow.com/questions/51735001/how-to-include-batch-size-in-pytorch-basic-example\n",
    "for epoch in range(5):\n",
    "    \n",
    "    running_loss = 0\n",
    "    n = 0\n",
    "    \n",
    "    print(f\"Epoch {epoch + 1}\\n-------------------------------\")\n",
    "\n",
    "    # Loop over batches in an epoch using DataLoader\n",
    "    for id_batch, (x_batch, y_batch) in enumerate(train_loader):\n",
    "        \n",
    "        x_batch = x_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "\n",
    "        y_batch_pred = model(x_batch, hidden_state)\n",
    "\n",
    "        loss = loss_fn(y_batch_pred[0], y_batch.float())\n",
    "        running_loss += loss.item()\n",
    "        n += 1\n",
    "\n",
    "        # backwards steps\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        \n",
    "    print(f\"Epoch {epoch + 1} loss: {running_loss/n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "53a492c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid = valid[[\"YR\", \"MON\", \"DAY\", \"HR\", \"WK\", 'ORIGIN_STAND']]\n",
    "\n",
    "X_valid_OH = encoder.transform(X_valid[X_valid.columns])\n",
    "\n",
    "X_valid = torch.Tensor(X_valid_OH).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fe6ec6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_state = (torch.zeros(1, hidden_size).to(device),\n",
    "                torch.zeros(1, hidden_size).to(device))\n",
    "valid_preds = model(X_valid)#[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "649f2786",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[711.6207],\n",
       "        [708.5093],\n",
       "        [714.1364],\n",
       "        ...,\n",
       "        [714.6372],\n",
       "        [719.8740],\n",
       "        [717.0795]], device='cuda:0', grad_fn=<LeakyReluBackward0>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80e663f",
   "metadata": {},
   "source": [
    "## Prediction file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3993752b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('test_public.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cc00fbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data[[\"YR\", \"MON\", \"DAY\", \"HR\", \"WK\"]] = (\n",
    "    test_data[[\"TIMESTAMP\"]].apply(parse_time, axis=1, result_type=\"expand\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1edbdda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_data[[\"YR\", \"MON\", \"DAY\", \"HR\", \"WK\", 'ORIGIN_STAND']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "842e0bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_OH = encoder.transform(X_test[X_test.columns])\n",
    "\n",
    "X_test = torch.Tensor(X_test_OH).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "95fee367",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model(X_test).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2b455519",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_preds = pd.DataFrame({'TRIP_ID': test_data['TRIP_ID'], 'TRAVEL_TIME': train['LEN'].mean()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "67208289",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_preds = pd.DataFrame({'TRIP_ID': test_data['TRIP_ID'], 'TRAVEL_TIME': preds.cpu().detach()})\n",
    "\n",
    "final_preds.to_csv('test_preds.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cab6213",
   "metadata": {},
   "source": [
    "# Old code, can ignore\n",
    "----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "31733b4d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "263863"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_fraction[train_fraction['ORIGIN_STAND'].isna()].shape[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2464fb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fraction = train.sample(500_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50de5428",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_fraction[[\"YR\", \"MON\", \"DAY\", \"HR\", \"WK\", 'ORIGIN_STAND']]\n",
    "y = train_fraction['LEN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b0ba5008",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_Y = torch.tensor(y.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d54f177",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_X = torch.from_numpy(X.values.astype('float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "80160ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = torch.nn.Sequential(\n",
    "torch.nn.Linear(6, 1))\n",
    "\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "# Define optimizer (this will perform your parameter updates use)\n",
    "lr = 5e-3\n",
    "opt = torch.optim.SGD(model_1.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c4fdadae",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = train.sample(500_000)\n",
    "X_test_pd = test[[\"YR\", \"MON\", \"DAY\", \"HR\", \"WK\", 'ORIGIN_STAND']]\n",
    "y_test_pd = test['LEN']\n",
    "\n",
    "y_test = torch.tensor(y_test_pd.values)\n",
    "X_test = torch.tensor(X_test_pd.values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc5bf0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/orenciolli/anaconda3/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([500000])) that is different to the input size (torch.Size([500000, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "train_err = []\n",
    "test_err = []\n",
    "parameters = []\n",
    "for i in range(100):\n",
    "    model_1.train()\n",
    "  \n",
    "    y_pred = model_1(full_X) # Compute model outputs\n",
    "    loss = loss_fn(y_pred, full_Y) # Compute MSE\n",
    "    opt.zero_grad() # Must reset the gradients every step. Otherwise, gradients from previous iterations would cause interference!!!\n",
    "    loss.backward() # Compute gradients of all parameters (our model) with respect to our computed loss value (a singular value)\n",
    "    opt.step() # One gradient step\n",
    "  \n",
    "    train_err.append(loss.item())\n",
    "  \n",
    "    model_1.eval()\n",
    "    with torch.no_grad():\n",
    "        test_err.append(loss_fn(model_1(X_test), y_test).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3b674c7d",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 must have the same dtype",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel_1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 must have the same dtype"
     ]
    }
   ],
   "source": [
    "model_1(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180cecf3",
   "metadata": {},
   "source": [
    "---------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c6237bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_fraction['POLYLINE'] = train_fraction['POLYLINE'].apply(lambda x: np.array(eval(x)).astype('float64'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "692e88a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_fraction.groupby('ORIGIN_STAND').mean(numeric_only = True).plot(kind = 'bar', y = 'TRIP_LENGTH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cc3907e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_fraction['ORIGIN_STAND'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fca3d86",
   "metadata": {},
   "source": [
    "Predicted important variables: polyline, interaction between timestamp and origin stand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "843ee5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(\n",
    "    train_fraction[['CALL_TYPE', 'ORIGIN_CALL', 'ORIGIN_STAND', 'TIMESTAMP', 'DAY_TYPE', 'POLYLINE']]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7482dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "826e758e",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_x = train_fraction['POLYLINE'].iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "025d0444",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_fraction['POLYLINE'].iloc[0].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d770a144",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dl/8n__h2151hd3n3gtfckwb75w0000gn/T/ipykernel_28498/3306076192.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  test_type = np.array([train_fraction['POLYLINE'].iloc[0], train_fraction['POLYLINE'].iloc[1]])\n"
     ]
    }
   ],
   "source": [
    "test_type = np.array([train_fraction['POLYLINE'].iloc[0], train_fraction['POLYLINE'].iloc[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3f95381f",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([\n",
    "    np.array([0.5, 1.0, 2.0], dtype=np.float16),\n",
    "    np.array([4.0, 6.0, 8.0], dtype=np.float16),\n",
    "])\n",
    "\n",
    "b = torch.from_numpy(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5c630dde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-8.59509"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(train_fraction['POLYLINE'])[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "eea24aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "three_d = np.array([\n",
    "    np.array([\n",
    "        np.array([1, 2]),\n",
    "        np.array([2, 3])\n",
    "    ]),\n",
    "    np.array([\n",
    "        np.array([1, 2]),\n",
    "        np.array([2, 3])\n",
    "    ])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "cb89d8aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2, 2)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "three_d.shape#[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "88d25ec4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-8.59509 , 41.146434])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_fraction['POLYLINE'].iloc[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c5b8cac9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2],\n",
       "         [2, 3]],\n",
       "\n",
       "        [[1, 2],\n",
       "         [2, 3]]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.from_numpy(three_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "abebfde0",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[89], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_fraction\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPOLYLINE\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool."
     ]
    }
   ],
   "source": [
    "torch.from_numpy(train_fraction['POLYLINE'].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b0a9c78e",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_fraction\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPOLYLINE\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool."
     ]
    }
   ],
   "source": [
    "torch.tensor(train_fraction['POLYLINE'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9c5fcd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
